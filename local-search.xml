<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>数据库常用压缩算法比较</title>
    <link href="/2022/11/08/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83/"/>
    <url>/2022/11/08/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83/</url>
    
    <content type="html"><![CDATA[<h2 id="比较不同压缩算法trade-off"><a href="#比较不同压缩算法trade-off" class="headerlink" title="比较不同压缩算法trade off"></a>比较不同压缩算法trade off</h2><p>压缩的本质是减少IO操作，从而带来更快的读写操作。需要用CPU周期来对IO性能进行tradeoff。</p><p>但是同时还要考虑到实际应用的性能需求，如实时性、吞吐等。不同压缩算法的cost不同，因此需要综合考虑。</p><h2 id="评估压缩算法的指标"><a href="#评估压缩算法的指标" class="headerlink" title="评估压缩算法的指标"></a>评估压缩算法的指标</h2><ul><li>压缩比 compression ratio</li><li>吞吐 throughput</li><li>压缩速度 compression speed</li><li>解压速度 decompression speed</li><li>内存 memory</li></ul><p>图中给出的是java-based benchmarking，重点比较gzip和snappy两种最通用的算法。</p><p>绿色的指标是compression ratio，越小越好；黄色的指标是throughput，越大越好。</p><p>gzip的压缩比例优于snappy，但snappy的吞吐高于gzip。</p><h2 id="如何选择适合的压缩算法"><a href="#如何选择适合的压缩算法" class="headerlink" title="如何选择适合的压缩算法"></a>如何选择适合的压缩算法</h2><ul><li>选择的压缩算法需要能够支持配置的big data environment（Spark、HIVE、presto、parquet、hadoop、S3、kafka等）</li><li>能够支持serialization format</li><li>考虑数据的生命周期以及访问模式！<br>（对于声明周期长但访问不频繁的cold data可以选择gzip压缩算法，频繁访问的hot data可以选择snappy压缩算法）</li><li>key wordload&amp;split-ability<br>（比如gzip就是不能支持split的数据，所以如果使用hadoop这种map reduce的应用，不选用gzip压缩算法）</li></ul><h2 id="Snappy压缩算法原理"><a href="#Snappy压缩算法原理" class="headerlink" title="Snappy压缩算法原理"></a>Snappy压缩算法原理</h2><p>snappy（又称zippy）是google开源的压缩算法，目标不是最大化压缩比例或者与其他压缩库的兼容性，而是压缩速度和合理的压缩比例。例如与zlib的最快模式相比，Snappy对于大多数输入都会快一个量级，但生成的压缩文件会大20%到100%。</p><p>snappy算法基于LZ77进行优化，因为LZ77的匹配过程时间复杂度太高。</p><p>具体可以参考 <a href="https://zzjw.cc/post/snappy/#snappy">https://zzjw.cc/post/snappy/#snappy</a></p><h2 id="Gzip压缩算法原理"><a href="#Gzip压缩算法原理" class="headerlink" title="Gzip压缩算法原理"></a>Gzip压缩算法原理</h2>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>压缩算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zipline论文笔记</title>
    <link href="/2022/11/08/Zipline%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/11/08/Zipline%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="研究问题-amp-动机"><a href="#研究问题-amp-动机" class="headerlink" title="研究问题&amp;动机"></a>研究问题&amp;动机</h2><p>将开销较大的压缩和解压offload到可编程交换机（line rate），实现的压缩算法是generalized deduplication。</p><p>现有一些工作会在交换机上对数据流做on-the-fly的压缩（），但是方法是在第三层及以上，Zipline是在layer2进行压缩，可以支持更广泛的传输协议。</p><p>IoT应用一般需要处理小数据块并且因为内存限制，需要对小数据块进行压缩。标准的压缩算法对小数据块的表现不够好，而GD对小数据块的压缩表现也很好。因此对于live vedio streaming，如果deflate这种算法需要足够量的数据才能有较好的性能，但是攒这么多数据需要时间，影响实时性。这种情况下选择GD更好。</p><h2 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h2><p>上图给出了压缩过程。</p><ol><li><p>接收到一个网络报文，包含数据payload B，长度为n个比特</p></li><li><p>使用Hamming decoder（会映射到Tofino内置的CRC模块，计算出来的结果是相同的）计算出一个m个比特长度的syndrome</p></li><li><p>用计算出的syndrome查表，得到一个对应长度为n的mask f</p></li><li><p>用查出的f与原本的数据按位异或，得到新的长度为n的b’</p></li><li><p>取b’最右的k位形成basis m</p></li><li><p>用m查basis-ID的表，看计算出来的basis是不是已经有一个更短的ID可以替换（从而达到压缩的目的）</p></li><li><p>如果表中用basis m能得到一个更短的ID，将包变成ID+syndrome；如果表中查不到对应的basis m，将包变成basis+syndrome</p></li></ol><p>（一开始不是很了解syndrome，参考了 <a href="https://www.youtube.com/watch?v=z89uW4eCRx0">https://www.youtube.com/watch?v=z89uW4eCRx0</a> 这个视频。）</p><img src="/2022/11/08/Zipline%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/decompression.png" class="" title="图片引用方法一"><p>同样，类似给出解压过程。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>P4可编程交换机</tag>
      
      <tag>压缩算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
